{
  "episode": 5,
  "average_reward": 0.0,
  "min_reward": -2.0,
  "max_reward": 2.0,
  "value_loss": 0.02,
  "policy_loss": 0.01,
  "entropy": 0.25,
  "explained_variance": null,
  "kl_divergence": null,
  "timestamp": "2025-09-27T16:53:28.015754"
}