"""
Safe File Manager for CogniForge

Ensures all file writes and process spawning are confined to the ./generated directory
for safety and organization. Prevents accidental writes to system directories.
"""

import os
import sys
import shutil
import tempfile
import subprocess
import hashlib
import json
from pathlib import Path
from typing import Optional, Union, List, Dict, Any, Tuple
from datetime import datetime
import logging
from contextlib import contextmanager
from enum import Enum

# Configure logging
logger = logging.getLogger(__name__)


class WriteScope(Enum):
    """Allowed write scopes for the file manager."""
    GENERATED = "generated"  # ./generated directory
    TEMP = "temp"           # ./generated/temp directory
    OUTPUTS = "outputs"     # ./generated/outputs directory
    MODELS = "models"       # ./generated/models directory
    LOGS = "logs"          # ./generated/logs directory
    CACHE = "cache"        # ./generated/cache directory


class SafeFileManager:
    """
    Manages file operations with restricted write scope.
    
    All write operations are confined to the ./generated directory tree
    to prevent accidental system modifications.
    """
    
    def __init__(self, base_dir: Optional[Path] = None, strict_mode: bool = True):
        """
        Initialize the safe file manager.
        
        Args:
            base_dir: Base directory for the project (defaults to current directory)
            strict_mode: If True, raises exceptions for unsafe operations
        """
        self.base_dir = Path(base_dir) if base_dir else Path.cwd()
        self.generated_dir = self.base_dir / "generated"
        self.strict_mode = strict_mode
        
        # Create directory structure
        self._initialize_directories()
        
        # Track all created files for cleanup
        self.created_files: List[Path] = []
        self.created_processes: List[subprocess.Popen] = []
        
        # Security settings
        self.max_file_size = 100 * 1024 * 1024  # 100 MB
        self.allowed_extensions = {
            '.py', '.txt', '.json', '.yaml', '.yml', '.md', '.csv',
            '.png', '.jpg', '.jpeg', '.gif', '.mp4', '.avi',
            '.pth', '.pkl', '.npy', '.npz', '.h5', '.hdf5',
            '.log', '.tmp', '.cache'
        }
        
        # Process restrictions
        self.allowed_commands = {
            'python', 'python3', 'pip', 'pip3',
            'git', 'ffmpeg', 'uvicorn',
            'pytest', 'black', 'flake8', 'mypy'
        }
        
        logger.info(f"SafeFileManager initialized with base: {self.generated_dir}")
    
    def _initialize_directories(self):
        """Create the directory structure for safe operations."""
        directories = [
            self.generated_dir,
            self.generated_dir / "temp",
            self.generated_dir / "outputs",
            self.generated_dir / "models",
            self.generated_dir / "logs",
            self.generated_dir / "cache",
            self.generated_dir / "code",
            self.generated_dir / "data",
            self.generated_dir / "recordings",
            self.generated_dir / "checkpoints"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
        
        # Create a README in the generated directory
        readme_path = self.generated_dir / "README.md"
        if not readme_path.exists():
            readme_content = """# Generated Files Directory

This directory contains all files generated by CogniForge operations.
All write operations are confined to this directory for safety.

## Directory Structure:
- `temp/` - Temporary files (automatically cleaned)
- `outputs/` - Final output files
- `models/` - Trained models and checkpoints
- `logs/` - Log files
- `cache/` - Cached data
- `code/` - Generated code
- `data/` - Processed data
- `recordings/` - Demo recordings
- `checkpoints/` - Training checkpoints

## Safety Features:
- All writes are confined to this directory
- File size limits enforced (100 MB default)
- Only safe file extensions allowed
- Process spawning restricted to safe commands
- Automatic cleanup on exit

Generated on: {datetime.now().isoformat()}
"""
            readme_path.write_text(readme_content, encoding='utf-8')
    
    def get_safe_path(self, filename: str, scope: WriteScope = WriteScope.OUTPUTS) -> Path:
        """
        Get a safe path for writing a file.
        
        Args:
            filename: Desired filename
            scope: Write scope (subdirectory)
            
        Returns:
            Safe path within the generated directory
            
        Raises:
            ValueError: If the filename is unsafe
        """
        # Clean the filename
        safe_filename = self._sanitize_filename(filename)
        
        # Check extension
        extension = Path(safe_filename).suffix.lower()
        if extension and extension not in self.allowed_extensions:
            if self.strict_mode:
                raise ValueError(f"File extension '{extension}' not allowed. "
                               f"Allowed: {self.allowed_extensions}")
            else:
                logger.warning(f"Unusual file extension: {extension}")
        
        # Construct safe path
        safe_path = self.generated_dir / scope.value / safe_filename
        
        # Ensure it's within our generated directory
        try:
            safe_path = safe_path.resolve()
            if not safe_path.is_relative_to(self.generated_dir):
                raise ValueError(f"Path escapes generated directory: {safe_path}")
        except (ValueError, RuntimeError) as e:
            if self.strict_mode:
                raise ValueError(f"Unsafe path: {filename}") from e
            else:
                # Fallback to a definitely safe path
                safe_path = self.generated_dir / scope.value / f"safe_{hashlib.md5(filename.encode()).hexdigest()[:8]}{extension}"
        
        return safe_path
    
    def _sanitize_filename(self, filename: str) -> str:
        """
        Sanitize a filename to remove dangerous characters.
        
        Args:
            filename: Original filename
            
        Returns:
            Sanitized filename
        """
        # Remove path traversal attempts
        filename = filename.replace("..", "")
        filename = filename.replace("\\", "_")
        filename = filename.replace("/", "_")
        
        # Remove other dangerous characters
        dangerous_chars = '<>:"|?*\x00'
        for char in dangerous_chars:
            filename = filename.replace(char, "_")
        
        # Limit length
        if len(filename) > 255:
            name, ext = os.path.splitext(filename)
            filename = name[:240] + ext
        
        # Ensure it has a name
        if not filename or filename.startswith('.'):
            filename = f"file_{datetime.now().strftime('%Y%m%d_%H%M%S')}{filename}"
        
        return filename
    
    @contextmanager
    def safe_write(self, filename: str, scope: WriteScope = WriteScope.OUTPUTS, 
                   mode: str = 'w', encoding: str = 'utf-8'):
        """
        Context manager for safe file writing.
        
        Args:
            filename: Desired filename
            scope: Write scope
            mode: File mode
            encoding: Text encoding
            
        Yields:
            File handle for writing
        """
        safe_path = self.get_safe_path(filename, scope)
        
        # Create parent directory if needed
        safe_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Track the file
        self.created_files.append(safe_path)
        
        try:
            if 'b' in mode:
                with open(safe_path, mode) as f:
                    yield f
            else:
                with open(safe_path, mode, encoding=encoding) as f:
                    yield f
            
            # Check file size after writing
            if safe_path.exists():
                size = safe_path.stat().st_size
                if size > self.max_file_size:
                    logger.warning(f"File exceeds size limit: {safe_path} ({size / 1024 / 1024:.1f} MB)")
                    if self.strict_mode:
                        safe_path.unlink()  # Delete oversized file
                        raise ValueError(f"File too large: {size} bytes > {self.max_file_size} bytes")
            
            logger.info(f"Safely wrote file: {safe_path}")
            
        except Exception as e:
            logger.error(f"Error writing file {safe_path}: {e}")
            raise
    
    def safe_write_json(self, data: Dict[str, Any], filename: str, 
                        scope: WriteScope = WriteScope.OUTPUTS) -> Path:
        """
        Safely write JSON data to a file.
        
        Args:
            data: JSON data to write
            filename: Desired filename
            scope: Write scope
            
        Returns:
            Path to the written file
        """
        if not filename.endswith('.json'):
            filename += '.json'
        
        safe_path = self.get_safe_path(filename, scope)
        
        with self.safe_write(filename, scope) as f:
            json.dump(data, f, indent=2)
        
        return safe_path
    
    def safe_spawn_process(self, command: List[str], 
                          cwd: Optional[Path] = None,
                          capture_output: bool = True,
                          timeout: Optional[float] = 300) -> subprocess.CompletedProcess:
        """
        Safely spawn a subprocess with restrictions.
        
        Args:
            command: Command and arguments
            cwd: Working directory (must be within generated/)
            capture_output: Whether to capture output
            timeout: Timeout in seconds
            
        Returns:
            Completed process
            
        Raises:
            ValueError: If command is unsafe
            subprocess.TimeoutExpired: If timeout exceeded
        """
        if not command:
            raise ValueError("Empty command")
        
        # Check if command is allowed
        base_command = Path(command[0]).name.lower()
        if base_command not in self.allowed_commands:
            if self.strict_mode:
                raise ValueError(f"Command '{base_command}' not allowed. "
                               f"Allowed: {self.allowed_commands}")
            else:
                logger.warning(f"Potentially unsafe command: {base_command}")
        
        # Ensure working directory is safe
        if cwd:
            cwd = Path(cwd).resolve()
            if not cwd.is_relative_to(self.generated_dir):
                cwd = self.generated_dir / "temp"
                logger.warning(f"Unsafe working directory, using: {cwd}")
        else:
            cwd = self.generated_dir / "temp"
        
        # Create log files for output
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        stdout_file = self.generated_dir / "logs" / f"{base_command}_{timestamp}_stdout.log"
        stderr_file = self.generated_dir / "logs" / f"{base_command}_{timestamp}_stderr.log"
        
        logger.info(f"Spawning process: {' '.join(command)}")
        logger.info(f"Working directory: {cwd}")
        
        try:
            # Run the process
            if capture_output:
                result = subprocess.run(
                    command,
                    cwd=cwd,
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                    check=False
                )
                
                # Save output to log files
                if result.stdout:
                    stdout_file.write_text(result.stdout)
                if result.stderr:
                    stderr_file.write_text(result.stderr)
                
            else:
                with open(stdout_file, 'w') as out, open(stderr_file, 'w') as err:
                    result = subprocess.run(
                        command,
                        cwd=cwd,
                        stdout=out,
                        stderr=err,
                        timeout=timeout,
                        check=False
                    )
            
            logger.info(f"Process completed with return code: {result.returncode}")
            return result
            
        except subprocess.TimeoutExpired as e:
            logger.error(f"Process timed out after {timeout} seconds")
            raise
        except Exception as e:
            logger.error(f"Error spawning process: {e}")
            raise
    
    def safe_temp_file(self, suffix: str = '.tmp', prefix: str = 'cogniforge_') -> Path:
        """
        Create a safe temporary file.
        
        Args:
            suffix: File suffix
            prefix: File prefix
            
        Returns:
            Path to temporary file
        """
        temp_dir = self.generated_dir / "temp"
        temp_dir.mkdir(exist_ok=True)
        
        # Create temp file
        fd, temp_path = tempfile.mkstemp(suffix=suffix, prefix=prefix, dir=temp_dir)
        os.close(fd)
        
        temp_path = Path(temp_path)
        self.created_files.append(temp_path)
        
        return temp_path
    
    def cleanup_temp_files(self, max_age_hours: float = 24):
        """
        Clean up old temporary files.
        
        Args:
            max_age_hours: Maximum age of temp files in hours
        """
        temp_dir = self.generated_dir / "temp"
        if not temp_dir.exists():
            return
        
        now = datetime.now()
        cleaned = 0
        
        for temp_file in temp_dir.iterdir():
            if temp_file.is_file():
                age_hours = (now - datetime.fromtimestamp(temp_file.stat().st_mtime)).total_seconds() / 3600
                if age_hours > max_age_hours:
                    try:
                        temp_file.unlink()
                        cleaned += 1
                    except Exception as e:
                        logger.warning(f"Could not delete temp file {temp_file}: {e}")
        
        if cleaned > 0:
            logger.info(f"Cleaned {cleaned} old temporary files")
    
    def get_storage_info(self) -> Dict[str, Any]:
        """
        Get information about storage usage in the generated directory.
        
        Returns:
            Dictionary with storage statistics
        """
        total_size = 0
        file_count = 0
        dir_sizes = {}
        
        for scope in WriteScope:
            scope_dir = self.generated_dir / scope.value
            if scope_dir.exists():
                scope_size = 0
                scope_files = 0
                
                for path in scope_dir.rglob('*'):
                    if path.is_file():
                        size = path.stat().st_size
                        scope_size += size
                        scope_files += 1
                
                dir_sizes[scope.value] = {
                    'size_bytes': scope_size,
                    'size_mb': scope_size / 1024 / 1024,
                    'file_count': scope_files
                }
                
                total_size += scope_size
                file_count += scope_files
        
        return {
            'total_size_bytes': total_size,
            'total_size_mb': total_size / 1024 / 1024,
            'total_files': file_count,
            'directories': dir_sizes,
            'created_files': len(self.created_files)
        }
    
    def cleanup_all(self):
        """Clean up all created files and terminate processes."""
        logger.info("Cleaning up all created files and processes...")
        
        # Terminate processes
        for process in self.created_processes:
            try:
                if process.poll() is None:
                    process.terminate()
                    process.wait(timeout=5)
            except Exception as e:
                logger.warning(f"Could not terminate process: {e}")
        
        # Clean temp files
        self.cleanup_temp_files(max_age_hours=0)
        
        logger.info("Cleanup complete")
    
    def __enter__(self):
        """Context manager entry."""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit with cleanup."""
        if exc_type is not None:
            logger.error(f"Exception in SafeFileManager: {exc_type.__name__}: {exc_val}")
        self.cleanup_all()


# Global instance for convenience
_global_manager: Optional[SafeFileManager] = None


def get_safe_manager() -> SafeFileManager:
    """Get or create the global safe file manager."""
    global _global_manager
    if _global_manager is None:
        _global_manager = SafeFileManager()
    return _global_manager


def safe_write(content: str, filename: str, scope: WriteScope = WriteScope.OUTPUTS) -> Path:
    """
    Convenience function for safe file writing.
    
    Args:
        content: Content to write
        filename: Desired filename
        scope: Write scope
        
    Returns:
        Path to written file
    """
    manager = get_safe_manager()
    safe_path = manager.get_safe_path(filename, scope)
    
    with manager.safe_write(filename, scope) as f:
        f.write(content)
    
    return safe_path


def safe_run(command: List[str], timeout: float = 300) -> subprocess.CompletedProcess:
    """
    Convenience function for safe process execution.
    
    Args:
        command: Command and arguments
        timeout: Timeout in seconds
        
    Returns:
        Completed process
    """
    manager = get_safe_manager()
    return manager.safe_spawn_process(command, timeout=timeout)


# Example usage
if __name__ == "__main__":
    import time
    
    print("Safe File Manager Demo")
    print("=" * 60)
    
    # Create manager
    with SafeFileManager() as manager:
        # Safe file write
        with manager.safe_write("test.txt", WriteScope.OUTPUTS) as f:
            f.write("Hello from safe file manager!\n")
            f.write("All writes are confined to ./generated/\n")
        
        # Safe JSON write
        data = {"safe": True, "timestamp": datetime.now().isoformat()}
        json_path = manager.safe_write_json(data, "config.json", WriteScope.OUTPUTS)
        print(f"Wrote JSON to: {json_path}")
        
        # Safe temp file
        temp_file = manager.safe_temp_file(suffix=".py")
        temp_file.write_text("# Temporary Python file\nprint('Hello')")
        print(f"Created temp file: {temp_file}")
        
        # Safe process execution
        try:
            result = manager.safe_spawn_process(
                ["python", "-c", "print('Hello from subprocess')"],
                timeout=5
            )
            print(f"Process output: {result.stdout}")
        except Exception as e:
            print(f"Process error: {e}")
        
        # Storage info
        info = manager.get_storage_info()
        print(f"\nStorage Info:")
        print(f"  Total size: {info['total_size_mb']:.2f} MB")
        print(f"  Total files: {info['total_files']}")
        
        # Cleanup will happen automatically when exiting context